{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "JQJ8uB_Pcszb"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import cv2\n",
    "import colorsys\n",
    "import imghdr\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "import scipy.io\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL \n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import struct\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import add, concatenate\n",
    "from tensorflow.keras.layers import Input, Lambda, Conv2D, BatchNormalization, LeakyReLU, ZeroPadding2D, UpSampling2D\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "WeMMZyTpEGA7"
   },
   "outputs": [],
   "source": [
    "def yolo_filter_boxes(box_confidence, boxes, box_class_probs, threshold = .6):\n",
    "    \"\"\"Filters YOLO boxes by thresholding on object and class confidence.\n",
    "    \n",
    "    Arguments:\n",
    "    box_confidence -- tensor of shape (19, 19, 5, 1)\n",
    "    boxes -- tensor of shape (19, 19, 5, 4)\n",
    "    box_probs -- tensor of shape (19, 19, 5, 1)\n",
    "    threshold -- real value, if [ highest class probability score < threshold], then get rid of the corresponding box\n",
    "    \n",
    "    Returns:\n",
    "    scores -- tensor of shape (None,), containing the class probability score for selected boxes\n",
    "    boxes -- tensor of shape (None, 4), containing (b_x, b_y, b_h, b_w) coordinates of selected boxes    \n",
    "    Note: \"None\" is here because you don't know the exact number of selected boxes, as it depends on the threshold. \n",
    "    For example, the actual output size of scores would be (10,) if there are 10 boxes.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Compute box scores\n",
    "    box_scores = box_confidence*box_class_probs\n",
    "    box_classes = K.argmax(box_scores, axis = -1)\n",
    "    box_class_scores = K.max(box_scores,-1)\n",
    "    \n",
    "    \n",
    "    # Step 2: Create a filtering mask based on \"box_scores\" by using \"threshold\". The mask should have the\n",
    "    # same dimension as box_scores, and be True for the boxes you want to keep (with probability >= threshold)\n",
    "    filtering_mask = box_class_scores >= threshold\n",
    "    \n",
    "    \n",
    "    # Step 3: Apply the mask to box_scores and boxes\n",
    "    scores = tf.boolean_mask(box_class_scores, filtering_mask)\n",
    "    boxes = tf.boolean_mask(boxes, filtering_mask)   \n",
    "    classes = tf.boolean_mask(box_classes, filtering_mask)    \n",
    "    \n",
    "    return scores, boxes, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hi8q4DK2ESmT",
    "outputId": "1c53bee3-c6ab-4763-cc48-82493a8ee343"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores[2] = 1.5909218\n",
      "boxes[2] = [ 8.426533   3.2713668 -0.5313436 -4.9413733]\n",
      "classes[2] = 0\n",
      "scores.shape = (None,)\n",
      "boxes.shape = (None, 4)\n",
      "classes.shape = (None,)\n"
     ]
    }
   ],
   "source": [
    "with  tf.compat.v1.Session() as test_a:\n",
    "    box_confidence = tf.random.normal([19, 19, 5, 1], mean=1, stddev=4, seed = 1)\n",
    "    boxes = tf.random.normal([19, 19, 5, 4], mean=1, stddev=4, seed = 1)\n",
    "    box_class_probs = tf.random.normal([19, 19, 5, 1], mean=1, stddev=4, seed = 1)\n",
    "    scores, boxes, classes = yolo_filter_boxes(box_confidence, boxes, box_class_probs, threshold = 0.5)\n",
    "    print(\"scores[2] = \" + str(scores[2].eval()))\n",
    "    print(\"boxes[2] = \" + str(boxes[2].eval()))\n",
    "    print(\"classes[2] = \" + str(classes[2].eval()))\n",
    "    print(\"scores.shape = \" + str(scores.shape))\n",
    "    print(\"boxes.shape = \" + str(boxes.shape))\n",
    "    print(\"classes.shape = \" + str(classes.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Y4sgBcQjEdg3"
   },
   "outputs": [],
   "source": [
    "def iou(box1, box2):\n",
    "    \"\"\"Implement the intersection over union (IoU) between box1 and box2\n",
    "    \n",
    "    Arguments:\n",
    "    box1 -- first box, list object with coordinates (box1_x1, box1_y1, box1_x2, box_1_y2)\n",
    "    box2 -- second box, list object with coordinates (box2_x1, box2_y1, box2_x2, box2_y2)\n",
    "    \"\"\"\n",
    "\n",
    "    # Assign variable names to coordinates for clarity\n",
    "    (box1_x1, box1_y1, box1_x2, box1_y2) = box1\n",
    "    (box2_x1, box2_y1, box2_x2, box2_y2) = box2\n",
    "        \n",
    "    # Calculate the (yi1, xi1, yi2, xi2) coordinates of the intersection of box1 and box2. Calculate its Area.\n",
    "    xi1 = max(box1[0], box2[0])\n",
    "    yi1 = max(box1[1], box2[1])\n",
    "    xi2 = min(box1[2], box2[2])\n",
    "    yi2 = min(box1[3], box2[3])\n",
    "    inter_width = max(xi2 - xi1, 0)\n",
    "    inter_height = max(yi2 - yi1, 0)\n",
    "    inter_area = inter_width * inter_height \n",
    "        \n",
    "    # Calculate the Union area by using Formula: Union(A,B) = A + B - Inter(A,B)\n",
    "    box1_area = (box1[3] - box1[1])*(box1[2] - box1[0])\n",
    "    box2_area = (box2[3] - box2[1])*(box2[2] - box2[0])\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "    \n",
    "    # compute the IoU\n",
    "    iou = inter_area / union_area\n",
    "    \n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bFDwjxkAEgLo",
    "outputId": "fb9f0e86-5a87-4f1e-ed8f-d60e3b47b716"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iou for intersecting boxes = 0.14285714285714285\n",
      "iou for non-intersecting boxes = 0.0\n",
      "iou for boxes that only touch at vertices = 0.0\n",
      "iou for boxes that only touch at edges = 0.0\n"
     ]
    }
   ],
   "source": [
    "## Test case 1: boxes intersect\n",
    "box1 = (2, 1, 4, 3)\n",
    "box2 = (1, 2, 3, 4) \n",
    "print(\"iou for intersecting boxes = \" + str(iou(box1, box2)))\n",
    "\n",
    "## Test case 2: boxes do not intersect\n",
    "box1 = (1,2,3,4)\n",
    "box2 = (5,6,7,8)\n",
    "print(\"iou for non-intersecting boxes = \" + str(iou(box1,box2)))\n",
    "\n",
    "## Test case 3: boxes intersect at vertices only\n",
    "box1 = (1,1,2,2)\n",
    "box2 = (2,2,3,3)\n",
    "print(\"iou for boxes that only touch at vertices = \" + str(iou(box1,box2)))\n",
    "\n",
    "## Test case 4: boxes intersect at edge only\n",
    "box1 = (1,1,3,3)\n",
    "box2 = (2,3,3,4)\n",
    "print(\"iou for boxes that only touch at edges = \" + str(iou(box1,box2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Jrw53WkUEkiP"
   },
   "outputs": [],
   "source": [
    "def yolo_non_max_suppression(scores, boxes, classes, max_boxes = 10, iou_threshold = 0.5):\n",
    "    \"\"\"\n",
    "    Applies Non-max suppression (NMS) to set of boxes\n",
    "    \n",
    "    Arguments:\n",
    "    scores -- tensor of shape (None,), output of yolo_filter_boxes()\n",
    "    boxes -- tensor of shape (None, 4), output of yolo_filter_boxes() that have been scaled to the image size (see later)\n",
    "    max_boxes -- integer, maximum number of predicted boxes you'd like\n",
    "    iou_threshold -- real value, \"intersection over union\" threshold used for NMS filtering\n",
    "    \n",
    "    Returns:\n",
    "    scores -- tensor of shape (, None), predicted score for each box\n",
    "    boxes -- tensor of shape (4, None), predicted box coordinates\n",
    "    \n",
    "    Note: The \"None\" dimension of the output tensors has obviously to be less than max_boxes. Note also that this\n",
    "    function will transpose the shapes of scores, boxes, classes. This is made for convenience.\n",
    "    \"\"\"\n",
    "    \n",
    "    # create max_box_tensor to be used in tf.image.non_max_suppression()\n",
    "    max_boxes_tensor = K.variable(max_boxes, dtype = 'int32')\n",
    "    \n",
    "    # initialize variable max_boxes_tensor\n",
    "    init= tf.compat.v1.variables_initializer([max_boxes_tensor])\n",
    "    #tf.compat.v1.keras.backend.get_session().run(init)\n",
    "    \n",
    "    # Use tf.image.non_max_suppression() to get the list of indices corresponding to boxes you keep\n",
    "    nms_indices = tf.image.non_max_suppression(boxes, scores, max_boxes, iou_threshold)\n",
    "    \n",
    "    # Use K.gather() to select only nms_indices from scores, boxes and classes\n",
    "    scores = K.gather(scores, nms_indices)\n",
    "    boxes = K.gather(boxes, nms_indices)\n",
    "    classes = K.gather(classes, nms_indices)\n",
    "    \n",
    "    return scores, boxes, classes\n",
    "\n",
    "def load_image_pixels(filename, shape):\n",
    "    # load image to get its shape\n",
    "    image = load_img(filename)\n",
    "    width, height = image.size\n",
    "\n",
    "    # load image with required size\n",
    "    image = load_img(filename, target_size=shape)\n",
    "    image = img_to_array(image)\n",
    "\n",
    "    # grayscale image normalization\n",
    "    image = image.astype('float32')\n",
    "    image /= 255.0\n",
    "\n",
    "    # add a dimension so that we have one sample\n",
    "    image = expand_dims(image, 0)\n",
    "    return image, width, height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MoHTa2KTEqSm",
    "outputId": "1b572db8-6795-4a58-d9b0-f2c1fb9ea8f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores[2] = 6.938395\n",
      "boxes[2] = [-5.299932    3.1379814   4.450367    0.95942086]\n",
      "classes[2] = -2.2452729\n",
      "scores.shape = (10,)\n",
      "boxes.shape = (10, 4)\n",
      "classes.shape = (10,)\n"
     ]
    }
   ],
   "source": [
    "with tf.compat.v1.Session() as test_b:\n",
    "    scores = tf.random.normal([54,], mean=1, stddev=4, seed = 1)\n",
    "    boxes = tf.random.normal([54, 4], mean=1, stddev=4, seed = 1)\n",
    "    classes = tf.random.normal([54,], mean=1, stddev=4, seed = 1)\n",
    "    scores, boxes, classes = yolo_non_max_suppression(scores, boxes, classes)\n",
    "    print(\"scores[2] = \" + str(scores[2].eval()))\n",
    "    print(\"boxes[2] = \" + str(boxes[2].eval()))\n",
    "    print(\"classes[2] = \" + str(classes[2].eval()))\n",
    "    print(\"scores.shape = \" + str(scores.eval().shape))\n",
    "    print(\"boxes.shape = \" + str(boxes.eval().shape))\n",
    "    print(\"classes.shape = \" + str(classes.eval().shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "qYGQx1weEy28"
   },
   "outputs": [],
   "source": [
    "#Do not make changes in these functions\n",
    "def scale_boxes(boxes, image_shape):\n",
    "    \"\"\" Scales the predicted boxes in order to be drawable on the image\"\"\"\n",
    "    height = image_shape[0]\n",
    "    width = image_shape[1]\n",
    "    image_dims = K.stack([height, width, height, width])\n",
    "    image_dims = K.reshape(image_dims, [1, 4])\n",
    "    boxes = boxes * image_dims\n",
    "    return boxes\n",
    "def yolo_boxes_to_corners(box_xy, box_wh):\n",
    "    \"\"\"Convert YOLO box predictions to bounding box corners.\"\"\"\n",
    "    box_mins = box_xy - (box_wh / 2.)\n",
    "    box_maxes = box_xy + (box_wh / 2.)\n",
    "\n",
    "    return K.concatenate([\n",
    "        box_mins[..., 1:2],  # y_min\n",
    "        box_mins[..., 0:1],  # x_min\n",
    "        box_maxes[..., 1:2],  # y_max\n",
    "        box_maxes[..., 0:1]  # x_max\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "kAcIVd4NE3rK"
   },
   "outputs": [],
   "source": [
    "def yolo_head(feats, anchors, num_classes):\n",
    "    \"\"\"Convert final layer features to bounding box parameters.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    feats : tensor\n",
    "        Final convolutional layer features.\n",
    "    anchors : array-like\n",
    "        Anchor box widths and heights.\n",
    "    num_classes : int\n",
    "        Number of target classes.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    box_xy : tensor\n",
    "        x, y box predictions adjusted by spatial location in conv layer.\n",
    "    box_wh : tensor\n",
    "        w, h box predictions adjusted by anchors and conv spatial resolution.\n",
    "    box_conf : tensor\n",
    "        Probability estimate for whether each box contains any object.\n",
    "    box_class_pred : tensor\n",
    "        Probability distribution estimate for each box over class labels.\n",
    "    \"\"\"\n",
    "    num_anchors = len(anchors)\n",
    "    # Reshape to batch, height, width, num_anchors, box_params.\n",
    "    anchors_tensor = K.reshape(K.variable(anchors), [1, 1, 3, num_anchors, 2]) #changed [1, 1, 1, num_anchors, 2] to [1, 1, 3, num_anchors, 2])\n",
    "    # Static implementation for fixed models.\n",
    "    # TODO: Remove or add option for static implementation.\n",
    "    # _, conv_height, conv_width, _ = K.int_shape(feats)\n",
    "    # conv_dims = K.variable([conv_width, conv_height])\n",
    "\n",
    "    # Dynamic implementation of conv dims for fully convolutional model.\n",
    "    conv_dims = K.shape(feats)[1:3]  # assuming channels last\n",
    "    # In YOLO the height index is the inner most iteration.\n",
    "    conv_height_index = K.arange(0, stop=conv_dims[0])\n",
    "    conv_width_index = K.arange(0, stop=conv_dims[1])\n",
    "    conv_height_index = K.tile(conv_height_index, [conv_dims[1]])\n",
    "\n",
    "    # TODO: Repeat_elements and tf.split doesn't support dynamic splits.\n",
    "    # conv_width_index = K.repeat_elements(conv_width_index, conv_dims[1], axis=0)\n",
    "    conv_width_index = K.tile(K.expand_dims(conv_width_index, 0), [conv_dims[0], 1])\n",
    "    conv_width_index = K.flatten(K.transpose(conv_width_index))\n",
    "    conv_index = K.transpose(K.stack([conv_height_index, conv_width_index]))\n",
    "    conv_index = K.reshape(conv_index, [1, conv_dims[0], conv_dims[1], 1, 2])\n",
    "    conv_index = K.cast(conv_index, K.dtype(feats))\n",
    "    \n",
    "    feats = K.reshape(feats, [-1, conv_dims[0], conv_dims[1], num_anchors, num_classes + 5])\n",
    "    conv_dims = K.cast(K.reshape(conv_dims, [1, 1, 1, 1, 2]), K.dtype(feats))\n",
    "\n",
    "    # Static generation of conv_index:\n",
    "    # conv_index = np.array([_ for _ in np.ndindex(conv_width, conv_height)])\n",
    "    # conv_index = conv_index[:, [1, 0]]  # swap columns for YOLO ordering.\n",
    "    # conv_index = K.variable(\n",
    "    #     conv_index.reshape(1, conv_height, conv_width, 1, 2))\n",
    "    # feats = Reshape(\n",
    "    #     (conv_dims[0], conv_dims[1], num_anchors, num_classes + 5))(feats)\n",
    "\n",
    "    box_confidence = K.sigmoid(feats[..., 4:5])\n",
    "    box_xy = K.sigmoid(feats[..., :2])\n",
    "    box_wh = K.exp(feats[..., 2:4])\n",
    "    box_class_probs = K.softmax(feats[..., 5:])\n",
    "\n",
    "    # Adjust preditions to each spatial grid point and anchor size.\n",
    "    # Note: YOLO iterates over height index before width index.\n",
    "    box_xy = (box_xy + conv_index) / conv_dims\n",
    "    box_wh = box_wh * anchors_tensor / conv_dims\n",
    "\n",
    "    return box_confidence, box_xy, box_wh, box_class_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "IUtxHCOgE7hR"
   },
   "outputs": [],
   "source": [
    "def yolo_eval(yolo_outputs, image_shape = (720., 1280.), max_boxes=10, score_threshold=.6, iou_threshold=.5):\n",
    "    \"\"\"\n",
    "    Converts the output of YOLO encoding (a lot of boxes) to your predicted boxes along with their scores, box coordinates and classes.\n",
    "    \n",
    "    Arguments:\n",
    "    yolo_outputs -- output of the encoding model (for image_shape of (608, 608, 3)), contains 4 tensors:\n",
    "                    box_confidence: tensor of shape (None, 19, 19, 5, 1)\n",
    "                    box_xy: tensor of shape (None, 19, 19, 5, 2)\n",
    "                    box_wh: tensor of shape (None, 19, 19, 5, 2)\n",
    "                    box_probs: tensor of shape (None, 19, 19, 5, 1)\n",
    "    image_shape -- tensor of shape (2,) containing the input shape, in this notebook we use (608., 608.) (has to be float32 dtype)\n",
    "    max_boxes -- integer, maximum number of predicted boxes you'd like\n",
    "    score_threshold -- real value, if [ highest probability score < threshold], then get rid of the corresponding box\n",
    "    iou_threshold -- real value, \"intersection over union\" threshold used for NMS filtering\n",
    "    \n",
    "    Returns:\n",
    "    scores -- tensor of shape (None, ), predicted score for each box\n",
    "    boxes -- tensor of shape (None, 4), predicted box coordinates\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve outputs of the YOLO model (≈1 line)\n",
    "    box_confidence, box_xy, box_wh, box_class_probs = yolo_outputs\n",
    "    \n",
    "    # Convert boxes to be ready for filtering functions (convert boxes box_xy and box_wh to corner coordinates)\n",
    "    boxes = yolo_boxes_to_corners(box_xy, box_wh)\n",
    "    \n",
    "    # Use one of the functions you've implemented to perform Score-filtering with a threshold of score_threshold (≈1 line)\n",
    "    scores, boxes, classes = yolo_filter_boxes(box_confidence, boxes, box_class_probs, threshold = score_threshold)\n",
    "    \n",
    "    # Scale boxes back to original image shape.\n",
    "    boxes = scale_boxes(boxes, image_shape)\n",
    "    \n",
    "    # Use one of the functions you've implemented to perform Non-max suppression with \n",
    "    # maximum number of boxes set to max_boxes and a threshold of iou_threshold (≈1 line)\n",
    "    scores, boxes, classes = yolo_non_max_suppression(scores, boxes, classes, max_boxes, iou_threshold)\n",
    "    \n",
    "    return scores, boxes, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dwDzzvQpFBev",
    "outputId": "30ebb416-ebe0-4821-a0ba-53ef941f3518"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores[2] = 138.79124\n",
      "boxes[2] = [1292.3297  -278.52167 3876.9893  -835.56494]\n",
      "classes[2] = 54\n",
      "scores.shape = (10,)\n",
      "boxes.shape = (10, 4)\n",
      "classes.shape = (10,)\n"
     ]
    }
   ],
   "source": [
    "with tf.compat.v1.Session() as test_b:\n",
    "    yolo_outputs = (tf.random.normal([19, 19, 5, 1], mean=1, stddev=4, seed = 1),\n",
    "                    tf.random.normal([19, 19, 5, 2], mean=1, stddev=4, seed = 1),\n",
    "                    tf.random.normal([19, 19, 5, 2], mean=1, stddev=4, seed = 1),\n",
    "                    tf.random.normal([19, 19, 5, 80], mean=1, stddev=4, seed = 1))\n",
    "    scores, boxes, classes = yolo_eval(yolo_outputs)\n",
    "    print(\"scores[2] = \" + str(scores[2].eval()))\n",
    "    print(\"boxes[2] = \" + str(boxes[2].eval()))\n",
    "    print(\"classes[2] = \" + str(classes[2].eval()))\n",
    "    print(\"scores.shape = \" + str(scores.eval().shape))\n",
    "    print(\"boxes.shape = \" + str(boxes.eval().shape))\n",
    "    print(\"classes.shape = \" + str(classes.eval().shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "dGbQlKJKFHqJ"
   },
   "outputs": [],
   "source": [
    "def preprocess_image(img_path, model_image_size):\n",
    "    image = Image.open(img_path)\n",
    "    resized_image = image.resize(tuple(reversed(model_image_size)), Image.BICUBIC)\n",
    "    image_data = np.array(resized_image, dtype='float32')\n",
    "    image_data /= 255.\n",
    "    image_data = np.expand_dims(image_data, 0)  # Add batch dimension.\n",
    "    return image, image_data\n",
    "\n",
    "def draw_boxes(image, out_scores, out_boxes, out_classes, class_names, colors):\n",
    "    \n",
    "    font = ImageFont.truetype(font='font/FiraMono-Medium.otf',size=np.floor(3e-2 * image.size[1] + 0.5).astype('int32'))\n",
    "    thickness = (image.size[0] + image.size[1]) // 300\n",
    "\n",
    "    for i, c in reversed(list(enumerate(out_classes))):\n",
    "        predicted_class = class_names[c]\n",
    "        box = out_boxes[i]\n",
    "        score = out_scores[i]\n",
    "\n",
    "        label = '{} {:.2f}'.format(predicted_class, score)\n",
    "\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        label_size = draw.textsize(label, font)\n",
    "\n",
    "        top, left, bottom, right = box\n",
    "        top = max(0, np.floor(top + 0.5).astype('int32'))\n",
    "        left = max(0, np.floor(left + 0.5).astype('int32'))\n",
    "        bottom = min(image.size[1], np.floor(bottom + 0.5).astype('int32'))\n",
    "        right = min(image.size[0], np.floor(right + 0.5).astype('int32'))\n",
    "        print(label, (left, top), (right, bottom))\n",
    "\n",
    "        if top - label_size[1] >= 0:\n",
    "            text_origin = np.array([left, top - label_size[1]])\n",
    "        else:\n",
    "            text_origin = np.array([left, top + 1])\n",
    "\n",
    "        for i in range(thickness):\n",
    "            draw.rectangle([left + i, top + i, right - i, bottom - i], outline=colors[c])\n",
    "        draw.rectangle([tuple(text_origin), tuple(text_origin + label_size)], fill=colors[c])\n",
    "        draw.text(text_origin, label, fill=(0, 0, 0), font=font)\n",
    "        del draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "7Z9WXy5SFK0_"
   },
   "outputs": [],
   "source": [
    "class WeightReader:\n",
    "\tdef __init__(self, weight_file):\n",
    "\t\twith open(weight_file,'rb') as w_f:\n",
    "\t\t\tmajor,\t= struct.unpack('i', w_f.read(4))\n",
    "\t\t\tminor,\t= struct.unpack('i', w_f.read(4))\n",
    "\t\t\trevision, = struct.unpack('i', w_f.read(4))\n",
    "\t\t\tif (major*10 + minor) >= 2 and major < 1000 and minor < 1000:\n",
    "\t\t\t\tw_f.read(8)\n",
    "\t\t\telse:\n",
    "\t\t\t\tw_f.read(4)\n",
    "\t\t\ttranspose = (major > 1000) or (minor > 1000)\n",
    "\t\t\tbinary = w_f.read()\n",
    "\t\tself.offset = 0\n",
    "\t\tself.all_weights = np.frombuffer(binary, dtype='float32')\n",
    " \n",
    "\tdef read_bytes(self, size):\n",
    "\t\tself.offset = self.offset + size\n",
    "\t\treturn self.all_weights[self.offset-size:self.offset]\n",
    " \n",
    "\tdef load_weights(self, model):\n",
    "\t\tfor i in range(106):\n",
    "\t\t\ttry:\n",
    "\t\t\t\tconv_layer = model.get_layer('conv_' + str(i))\n",
    "\t\t\t\tprint(\"loading weights of convolution #\" + str(i))\n",
    "\t\t\t\tif i not in [81, 93, 105]:\n",
    "\t\t\t\t\tnorm_layer = model.get_layer('bnorm_' + str(i))\n",
    "\t\t\t\t\tsize = np.prod(norm_layer.get_weights()[0].shape)\n",
    "\t\t\t\t\tbeta  = self.read_bytes(size) # bias\n",
    "\t\t\t\t\tgamma = self.read_bytes(size) # scale\n",
    "\t\t\t\t\tmean  = self.read_bytes(size) # mean\n",
    "\t\t\t\t\tvar   = self.read_bytes(size) # variance\n",
    "\t\t\t\t\tweights = norm_layer.set_weights([gamma, beta, mean, var])\n",
    "\t\t\t\tif len(conv_layer.get_weights()) > 1:\n",
    "\t\t\t\t\tbias   = self.read_bytes(np.prod(conv_layer.get_weights()[1].shape))\n",
    "\t\t\t\t\tkernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
    "\t\t\t\t\tkernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
    "\t\t\t\t\tkernel = kernel.transpose([2,3,1,0])\n",
    "\t\t\t\t\tconv_layer.set_weights([kernel, bias])\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tkernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
    "\t\t\t\t\tkernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
    "\t\t\t\t\tkernel = kernel.transpose([2,3,1,0])\n",
    "\t\t\t\t\tconv_layer.set_weights([kernel])\n",
    "\t\t\texcept ValueError:\n",
    "\t\t\t\tprint(\"no convolution #\" + str(i))\n",
    " \n",
    "\tdef reset(self):\n",
    "\t\tself.offset = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "8U83BKLxFQ5k"
   },
   "outputs": [],
   "source": [
    "def _conv_block(inp, convs, skip=True):\n",
    "\tx = inp\n",
    "\tcount = 0\n",
    "\tfor conv in convs:\n",
    "\t\tif count == (len(convs) - 2) and skip:\n",
    "\t\t\tskip_connection = x\n",
    "\t\tcount += 1\n",
    "\t\tif conv['stride'] > 1: x = ZeroPadding2D(((1,0),(1,0)))(x) # peculiar padding as darknet prefer left and top\n",
    "\t\tx = Conv2D(conv['filter'],\n",
    "\t\t\t\t   conv['kernel'],\n",
    "\t\t\t\t   strides=conv['stride'],\n",
    "\t\t\t\t   padding='valid' if conv['stride'] > 1 else 'same', # peculiar padding as darknet prefer left and top\n",
    "\t\t\t\t   name='conv_' + str(conv['layer_idx']),\n",
    "\t\t\t\t   use_bias=False if conv['bnorm'] else True)(x)\n",
    "\t\tif conv['bnorm']: x = BatchNormalization(epsilon=0.001, name='bnorm_' + str(conv['layer_idx']))(x)\n",
    "\t\tif conv['leaky']: x = LeakyReLU(alpha=0.1, name='leaky_' + str(conv['layer_idx']))(x)\n",
    "\treturn add([skip_connection, x]) if skip else x\n",
    "\n",
    "def make_yolov3_model():\n",
    "\tinput_image = Input(shape=(608, 608, 3))\n",
    "\t# Layer  0 => 4\n",
    "\tx = _conv_block(input_image, [{'filter': 32, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 0},\n",
    "\t\t\t\t\t\t\t\t  {'filter': 64, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 1},\n",
    "\t\t\t\t\t\t\t\t  {'filter': 32, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 2},\n",
    "\t\t\t\t\t\t\t\t  {'filter': 64, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 3}])\n",
    "\t# Layer  5 => 8\n",
    "\tx = _conv_block(x, [{'filter': 128, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 5},\n",
    "\t\t\t\t\t\t{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 6},\n",
    "\t\t\t\t\t\t{'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 7}])\n",
    "\t# Layer  9 => 11\n",
    "\tx = _conv_block(x, [{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 9},\n",
    "\t\t\t\t\t\t{'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 10}])\n",
    "\t# Layer 12 => 15\n",
    "\tx = _conv_block(x, [{'filter': 256, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 12},\n",
    "\t\t\t\t\t\t{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 13},\n",
    "\t\t\t\t\t\t{'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 14}])\n",
    "\t# Layer 16 => 36\n",
    "\tfor i in range(7):\n",
    "\t\tx = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 16+i*3},\n",
    "\t\t\t\t\t\t\t{'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 17+i*3}])\n",
    "\tskip_36 = x\n",
    "\t# Layer 37 => 40\n",
    "\tx = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 37},\n",
    "\t\t\t\t\t\t{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 38},\n",
    "\t\t\t\t\t\t{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 39}])\n",
    "\t# Layer 41 => 61\n",
    "\tfor i in range(7):\n",
    "\t\tx = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 41+i*3},\n",
    "\t\t\t\t\t\t\t{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 42+i*3}])\n",
    "\tskip_61 = x\n",
    "\t# Layer 62 => 65\n",
    "\tx = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 62},\n",
    "\t\t\t\t\t\t{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 63},\n",
    "\t\t\t\t\t\t{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 64}])\n",
    "\t# Layer 66 => 74\n",
    "\tfor i in range(3):\n",
    "\t\tx = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 66+i*3},\n",
    "\t\t\t\t\t\t\t{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 67+i*3}])\n",
    "\t# Layer 75 => 79\n",
    "\tx = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 75},\n",
    "\t\t\t\t\t\t{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 76},\n",
    "\t\t\t\t\t\t{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 77},\n",
    "\t\t\t\t\t\t{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 78},\n",
    "\t\t\t\t\t\t{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 79}], skip=False)\n",
    "\t# Layer 80 => 82\n",
    "\tyolo_82 = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 80},\n",
    "\t\t\t\t\t\t\t  {'filter':  425, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 81}], skip=False) #filter changed to 425\n",
    " # Layer 83 => 86\n",
    "\tx = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 84}], skip=False)\n",
    "\tx = UpSampling2D(2)(x)\n",
    "\tx = concatenate([x, skip_61])\n",
    "\t# Layer 87 => 91\n",
    "\tx = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 87},\n",
    "\t\t\t\t\t\t{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 88},\n",
    "\t\t\t\t\t\t{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 89},\n",
    "\t\t\t\t\t\t{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 90},\n",
    "\t\t\t\t\t\t{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 91}], skip=False)\n",
    "\t# Layer 92 => 94\n",
    "\tyolo_94 = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 92},\n",
    "\t\t\t\t\t\t\t  {'filter': 425, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 93}], skip=False) #filter changed to 425\n",
    "\t# Layer 95 => 98\n",
    "\tx = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True,   'layer_idx': 96}], skip=False)\n",
    "\tx = UpSampling2D(2)(x)\n",
    "\tx = concatenate([x, skip_36])\n",
    "\t# Layer 99 => 106\n",
    "\tyolo_106 = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 99},\n",
    "\t\t\t\t\t\t\t   {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 100},\n",
    "\t\t\t\t\t\t\t   {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 101},\n",
    "\t\t\t\t\t\t\t   {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 102},\n",
    "\t\t\t\t\t\t\t   {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 103},\n",
    "\t\t\t\t\t\t\t   {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 104},\n",
    "\t\t\t\t\t\t\t   {'filter': 425, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 105}], skip=False) #filter changed to 425\n",
    "\tmodel = Model(input_image, [yolo_82])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MKNpApPdFUT1",
    "outputId": "26ba54c3-9c13-4a74-db56-5e354ad434e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights of convolution #0\n",
      "loading weights of convolution #1\n",
      "loading weights of convolution #2\n",
      "loading weights of convolution #3\n",
      "no convolution #4\n",
      "loading weights of convolution #5\n",
      "loading weights of convolution #6\n",
      "loading weights of convolution #7\n",
      "no convolution #8\n",
      "loading weights of convolution #9\n",
      "loading weights of convolution #10\n",
      "no convolution #11\n",
      "loading weights of convolution #12\n",
      "loading weights of convolution #13\n",
      "loading weights of convolution #14\n",
      "no convolution #15\n",
      "loading weights of convolution #16\n",
      "loading weights of convolution #17\n",
      "no convolution #18\n",
      "loading weights of convolution #19\n",
      "loading weights of convolution #20\n",
      "no convolution #21\n",
      "loading weights of convolution #22\n",
      "loading weights of convolution #23\n",
      "no convolution #24\n",
      "loading weights of convolution #25\n",
      "loading weights of convolution #26\n",
      "no convolution #27\n",
      "loading weights of convolution #28\n",
      "loading weights of convolution #29\n",
      "no convolution #30\n",
      "loading weights of convolution #31\n",
      "loading weights of convolution #32\n",
      "no convolution #33\n",
      "loading weights of convolution #34\n",
      "loading weights of convolution #35\n",
      "no convolution #36\n",
      "loading weights of convolution #37\n",
      "loading weights of convolution #38\n",
      "loading weights of convolution #39\n",
      "no convolution #40\n",
      "loading weights of convolution #41\n",
      "loading weights of convolution #42\n",
      "no convolution #43\n",
      "loading weights of convolution #44\n",
      "loading weights of convolution #45\n",
      "no convolution #46\n",
      "loading weights of convolution #47\n",
      "no convolution #47\n",
      "loading weights of convolution #48\n",
      "no convolution #48\n",
      "no convolution #49\n",
      "loading weights of convolution #50\n",
      "no convolution #50\n",
      "loading weights of convolution #51\n",
      "no convolution #51\n",
      "no convolution #52\n",
      "loading weights of convolution #53\n",
      "no convolution #53\n",
      "loading weights of convolution #54\n",
      "no convolution #54\n",
      "no convolution #55\n",
      "loading weights of convolution #56\n",
      "no convolution #56\n",
      "loading weights of convolution #57\n",
      "no convolution #57\n",
      "no convolution #58\n",
      "loading weights of convolution #59\n",
      "no convolution #59\n",
      "loading weights of convolution #60\n",
      "no convolution #60\n",
      "no convolution #61\n",
      "loading weights of convolution #62\n",
      "no convolution #62\n",
      "loading weights of convolution #63\n",
      "no convolution #63\n",
      "loading weights of convolution #64\n",
      "no convolution #64\n",
      "no convolution #65\n",
      "loading weights of convolution #66\n",
      "no convolution #66\n",
      "loading weights of convolution #67\n",
      "no convolution #67\n",
      "no convolution #68\n",
      "loading weights of convolution #69\n",
      "no convolution #69\n",
      "loading weights of convolution #70\n",
      "no convolution #70\n",
      "no convolution #71\n",
      "loading weights of convolution #72\n",
      "no convolution #72\n",
      "loading weights of convolution #73\n",
      "no convolution #73\n",
      "no convolution #74\n",
      "loading weights of convolution #75\n",
      "no convolution #75\n",
      "loading weights of convolution #76\n",
      "no convolution #76\n",
      "loading weights of convolution #77\n",
      "no convolution #77\n",
      "loading weights of convolution #78\n",
      "no convolution #78\n",
      "loading weights of convolution #79\n",
      "no convolution #79\n",
      "loading weights of convolution #80\n",
      "no convolution #80\n",
      "loading weights of convolution #81\n",
      "no convolution #81\n",
      "no convolution #82\n",
      "no convolution #83\n",
      "no convolution #84\n",
      "no convolution #85\n",
      "no convolution #86\n",
      "no convolution #87\n",
      "no convolution #88\n",
      "no convolution #89\n",
      "no convolution #90\n",
      "no convolution #91\n",
      "no convolution #92\n",
      "no convolution #93\n",
      "no convolution #94\n",
      "no convolution #95\n",
      "no convolution #96\n",
      "no convolution #97\n",
      "no convolution #98\n",
      "no convolution #99\n",
      "no convolution #100\n",
      "no convolution #101\n",
      "no convolution #102\n",
      "no convolution #103\n",
      "no convolution #104\n",
      "no convolution #105\n"
     ]
    }
   ],
   "source": [
    "# define the yolo v3 model\n",
    "yolov3 = make_yolov3_model()\n",
    "\n",
    "# load the weights\n",
    "weight_reader = WeightReader('yolov3-wider_16000.weights')\n",
    "\n",
    "# set the weights\n",
    "weight_reader.load_weights(yolov3)\n",
    "\n",
    "# save the model to file\n",
    "yolov3.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "wtP5t8YAcSoe"
   },
   "outputs": [],
   "source": [
    "sess = tf.compat.v1.keras.backend.get_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "ZQG6zKiXcU67"
   },
   "outputs": [],
   "source": [
    "class_names = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\",\n",
    "\t\"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\",\n",
    "\t\"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\",\n",
    "\t\"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\",\n",
    "\t\"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\",\n",
    "\t\"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\",\n",
    "\t\"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\",\n",
    "\t\"chair\", \"sofa\", \"pottedplant\", \"bed\", \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\",\n",
    "\t\"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\",\n",
    "\t\"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"]\n",
    "anchors = [[10,13,  16,30,  33,23], [30,61, 62,45, 59,119], [116,90,  156,198,  373,326]]\n",
    "image_shape = (720., 1280.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2YXoi1hLcYr6",
    "outputId": "09149e5a-7cf8-4a27-cdd1-2da50ff10e0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "yolo_model = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KaEK3O7VccNh",
    "outputId": "3a7308bf-9825-47aa-8d6c-da8de3251e60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 608, 608, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_0 (Conv2D)                 (None, 608, 608, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_0 (BatchNormalization)    (None, 608, 608, 32) 128         conv_0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_0 (LeakyReLU)             (None, 608, 608, 32) 0           bnorm_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2D)  (None, 609, 609, 32) 0           leaky_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_1 (Conv2D)                 (None, 304, 304, 64) 18432       zero_padding2d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_1 (BatchNormalization)    (None, 304, 304, 64) 256         conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_1 (LeakyReLU)             (None, 304, 304, 64) 0           bnorm_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_2 (Conv2D)                 (None, 304, 304, 32) 2048        leaky_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_2 (BatchNormalization)    (None, 304, 304, 32) 128         conv_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_2 (LeakyReLU)             (None, 304, 304, 32) 0           bnorm_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_3 (Conv2D)                 (None, 304, 304, 64) 18432       leaky_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_3 (BatchNormalization)    (None, 304, 304, 64) 256         conv_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_3 (LeakyReLU)             (None, 304, 304, 64) 0           bnorm_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 304, 304, 64) 0           leaky_1[0][0]                    \n",
      "                                                                 leaky_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 305, 305, 64) 0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv_5 (Conv2D)                 (None, 152, 152, 128 73728       zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_5 (BatchNormalization)    (None, 152, 152, 128 512         conv_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_5 (LeakyReLU)             (None, 152, 152, 128 0           bnorm_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_6 (Conv2D)                 (None, 152, 152, 64) 8192        leaky_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_6 (BatchNormalization)    (None, 152, 152, 64) 256         conv_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_6 (LeakyReLU)             (None, 152, 152, 64) 0           bnorm_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_7 (Conv2D)                 (None, 152, 152, 128 73728       leaky_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_7 (BatchNormalization)    (None, 152, 152, 128 512         conv_7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_7 (LeakyReLU)             (None, 152, 152, 128 0           bnorm_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 152, 152, 128 0           leaky_5[0][0]                    \n",
      "                                                                 leaky_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_9 (Conv2D)                 (None, 152, 152, 64) 8192        add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_9 (BatchNormalization)    (None, 152, 152, 64) 256         conv_9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_9 (LeakyReLU)             (None, 152, 152, 64) 0           bnorm_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_10 (Conv2D)                (None, 152, 152, 128 73728       leaky_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_10 (BatchNormalization)   (None, 152, 152, 128 512         conv_10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_10 (LeakyReLU)            (None, 152, 152, 128 0           bnorm_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 152, 152, 128 0           add_1[0][0]                      \n",
      "                                                                 leaky_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 153, 153, 128 0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv_12 (Conv2D)                (None, 76, 76, 256)  294912      zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_12 (BatchNormalization)   (None, 76, 76, 256)  1024        conv_12[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_12 (LeakyReLU)            (None, 76, 76, 256)  0           bnorm_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_13 (Conv2D)                (None, 76, 76, 128)  32768       leaky_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_13 (BatchNormalization)   (None, 76, 76, 128)  512         conv_13[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_13 (LeakyReLU)            (None, 76, 76, 128)  0           bnorm_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_14 (Conv2D)                (None, 76, 76, 256)  294912      leaky_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_14 (BatchNormalization)   (None, 76, 76, 256)  1024        conv_14[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_14 (LeakyReLU)            (None, 76, 76, 256)  0           bnorm_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 76, 76, 256)  0           leaky_12[0][0]                   \n",
      "                                                                 leaky_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_16 (Conv2D)                (None, 76, 76, 128)  32768       add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_16 (BatchNormalization)   (None, 76, 76, 128)  512         conv_16[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_16 (LeakyReLU)            (None, 76, 76, 128)  0           bnorm_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_17 (Conv2D)                (None, 76, 76, 256)  294912      leaky_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_17 (BatchNormalization)   (None, 76, 76, 256)  1024        conv_17[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_17 (LeakyReLU)            (None, 76, 76, 256)  0           bnorm_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 76, 76, 256)  0           add_3[0][0]                      \n",
      "                                                                 leaky_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_19 (Conv2D)                (None, 76, 76, 128)  32768       add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_19 (BatchNormalization)   (None, 76, 76, 128)  512         conv_19[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_19 (LeakyReLU)            (None, 76, 76, 128)  0           bnorm_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_20 (Conv2D)                (None, 76, 76, 256)  294912      leaky_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_20 (BatchNormalization)   (None, 76, 76, 256)  1024        conv_20[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_20 (LeakyReLU)            (None, 76, 76, 256)  0           bnorm_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 76, 76, 256)  0           add_4[0][0]                      \n",
      "                                                                 leaky_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_22 (Conv2D)                (None, 76, 76, 128)  32768       add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_22 (BatchNormalization)   (None, 76, 76, 128)  512         conv_22[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_22 (LeakyReLU)            (None, 76, 76, 128)  0           bnorm_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_23 (Conv2D)                (None, 76, 76, 256)  294912      leaky_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_23 (BatchNormalization)   (None, 76, 76, 256)  1024        conv_23[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_23 (LeakyReLU)            (None, 76, 76, 256)  0           bnorm_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 76, 76, 256)  0           add_5[0][0]                      \n",
      "                                                                 leaky_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_25 (Conv2D)                (None, 76, 76, 128)  32768       add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_25 (BatchNormalization)   (None, 76, 76, 128)  512         conv_25[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_25 (LeakyReLU)            (None, 76, 76, 128)  0           bnorm_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_26 (Conv2D)                (None, 76, 76, 256)  294912      leaky_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_26 (BatchNormalization)   (None, 76, 76, 256)  1024        conv_26[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_26 (LeakyReLU)            (None, 76, 76, 256)  0           bnorm_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 76, 76, 256)  0           add_6[0][0]                      \n",
      "                                                                 leaky_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_28 (Conv2D)                (None, 76, 76, 128)  32768       add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_28 (BatchNormalization)   (None, 76, 76, 128)  512         conv_28[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_28 (LeakyReLU)            (None, 76, 76, 128)  0           bnorm_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_29 (Conv2D)                (None, 76, 76, 256)  294912      leaky_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_29 (BatchNormalization)   (None, 76, 76, 256)  1024        conv_29[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_29 (LeakyReLU)            (None, 76, 76, 256)  0           bnorm_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 76, 76, 256)  0           add_7[0][0]                      \n",
      "                                                                 leaky_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_31 (Conv2D)                (None, 76, 76, 128)  32768       add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_31 (BatchNormalization)   (None, 76, 76, 128)  512         conv_31[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_31 (LeakyReLU)            (None, 76, 76, 128)  0           bnorm_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_32 (Conv2D)                (None, 76, 76, 256)  294912      leaky_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_32 (BatchNormalization)   (None, 76, 76, 256)  1024        conv_32[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_32 (LeakyReLU)            (None, 76, 76, 256)  0           bnorm_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 76, 76, 256)  0           add_8[0][0]                      \n",
      "                                                                 leaky_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_34 (Conv2D)                (None, 76, 76, 128)  32768       add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_34 (BatchNormalization)   (None, 76, 76, 128)  512         conv_34[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_34 (LeakyReLU)            (None, 76, 76, 128)  0           bnorm_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_35 (Conv2D)                (None, 76, 76, 256)  294912      leaky_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_35 (BatchNormalization)   (None, 76, 76, 256)  1024        conv_35[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_35 (LeakyReLU)            (None, 76, 76, 256)  0           bnorm_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 76, 76, 256)  0           add_9[0][0]                      \n",
      "                                                                 leaky_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPadding2D (None, 77, 77, 256)  0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_37 (Conv2D)                (None, 38, 38, 512)  1179648     zero_padding2d_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_37 (BatchNormalization)   (None, 38, 38, 512)  2048        conv_37[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_37 (LeakyReLU)            (None, 38, 38, 512)  0           bnorm_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_38 (Conv2D)                (None, 38, 38, 256)  131072      leaky_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_38 (BatchNormalization)   (None, 38, 38, 256)  1024        conv_38[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_38 (LeakyReLU)            (None, 38, 38, 256)  0           bnorm_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_39 (Conv2D)                (None, 38, 38, 512)  1179648     leaky_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_39 (BatchNormalization)   (None, 38, 38, 512)  2048        conv_39[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_39 (LeakyReLU)            (None, 38, 38, 512)  0           bnorm_39[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 38, 38, 512)  0           leaky_37[0][0]                   \n",
      "                                                                 leaky_39[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_41 (Conv2D)                (None, 38, 38, 256)  131072      add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_41 (BatchNormalization)   (None, 38, 38, 256)  1024        conv_41[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_41 (LeakyReLU)            (None, 38, 38, 256)  0           bnorm_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_42 (Conv2D)                (None, 38, 38, 512)  1179648     leaky_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_42 (BatchNormalization)   (None, 38, 38, 512)  2048        conv_42[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_42 (LeakyReLU)            (None, 38, 38, 512)  0           bnorm_42[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 38, 38, 512)  0           add_11[0][0]                     \n",
      "                                                                 leaky_42[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_44 (Conv2D)                (None, 38, 38, 256)  131072      add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_44 (BatchNormalization)   (None, 38, 38, 256)  1024        conv_44[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_44 (LeakyReLU)            (None, 38, 38, 256)  0           bnorm_44[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_45 (Conv2D)                (None, 38, 38, 512)  1179648     leaky_44[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_45 (BatchNormalization)   (None, 38, 38, 512)  2048        conv_45[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_45 (LeakyReLU)            (None, 38, 38, 512)  0           bnorm_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 38, 38, 512)  0           add_12[0][0]                     \n",
      "                                                                 leaky_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_47 (Conv2D)                (None, 38, 38, 256)  131072      add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_47 (BatchNormalization)   (None, 38, 38, 256)  1024        conv_47[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_47 (LeakyReLU)            (None, 38, 38, 256)  0           bnorm_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_48 (Conv2D)                (None, 38, 38, 512)  1179648     leaky_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_48 (BatchNormalization)   (None, 38, 38, 512)  2048        conv_48[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_48 (LeakyReLU)            (None, 38, 38, 512)  0           bnorm_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 38, 38, 512)  0           add_13[0][0]                     \n",
      "                                                                 leaky_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_50 (Conv2D)                (None, 38, 38, 256)  131072      add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_50 (BatchNormalization)   (None, 38, 38, 256)  1024        conv_50[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_50 (LeakyReLU)            (None, 38, 38, 256)  0           bnorm_50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_51 (Conv2D)                (None, 38, 38, 512)  1179648     leaky_50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_51 (BatchNormalization)   (None, 38, 38, 512)  2048        conv_51[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_51 (LeakyReLU)            (None, 38, 38, 512)  0           bnorm_51[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 38, 38, 512)  0           add_14[0][0]                     \n",
      "                                                                 leaky_51[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_53 (Conv2D)                (None, 38, 38, 256)  131072      add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_53 (BatchNormalization)   (None, 38, 38, 256)  1024        conv_53[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_53 (LeakyReLU)            (None, 38, 38, 256)  0           bnorm_53[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_54 (Conv2D)                (None, 38, 38, 512)  1179648     leaky_53[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_54 (BatchNormalization)   (None, 38, 38, 512)  2048        conv_54[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_54 (LeakyReLU)            (None, 38, 38, 512)  0           bnorm_54[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 38, 38, 512)  0           add_15[0][0]                     \n",
      "                                                                 leaky_54[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_56 (Conv2D)                (None, 38, 38, 256)  131072      add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_56 (BatchNormalization)   (None, 38, 38, 256)  1024        conv_56[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_56 (LeakyReLU)            (None, 38, 38, 256)  0           bnorm_56[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_57 (Conv2D)                (None, 38, 38, 512)  1179648     leaky_56[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_57 (BatchNormalization)   (None, 38, 38, 512)  2048        conv_57[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_57 (LeakyReLU)            (None, 38, 38, 512)  0           bnorm_57[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 38, 38, 512)  0           add_16[0][0]                     \n",
      "                                                                 leaky_57[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_59 (Conv2D)                (None, 38, 38, 256)  131072      add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_59 (BatchNormalization)   (None, 38, 38, 256)  1024        conv_59[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_59 (LeakyReLU)            (None, 38, 38, 256)  0           bnorm_59[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_60 (Conv2D)                (None, 38, 38, 512)  1179648     leaky_59[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_60 (BatchNormalization)   (None, 38, 38, 512)  2048        conv_60[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_60 (LeakyReLU)            (None, 38, 38, 512)  0           bnorm_60[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 38, 38, 512)  0           add_17[0][0]                     \n",
      "                                                                 leaky_60[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPadding2D (None, 39, 39, 512)  0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_62 (Conv2D)                (None, 19, 19, 1024) 4718592     zero_padding2d_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_62 (BatchNormalization)   (None, 19, 19, 1024) 4096        conv_62[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_62 (LeakyReLU)            (None, 19, 19, 1024) 0           bnorm_62[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_63 (Conv2D)                (None, 19, 19, 512)  524288      leaky_62[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_63 (BatchNormalization)   (None, 19, 19, 512)  2048        conv_63[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_63 (LeakyReLU)            (None, 19, 19, 512)  0           bnorm_63[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_64 (Conv2D)                (None, 19, 19, 1024) 4718592     leaky_63[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_64 (BatchNormalization)   (None, 19, 19, 1024) 4096        conv_64[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_64 (LeakyReLU)            (None, 19, 19, 1024) 0           bnorm_64[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 19, 19, 1024) 0           leaky_62[0][0]                   \n",
      "                                                                 leaky_64[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_66 (Conv2D)                (None, 19, 19, 512)  524288      add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_66 (BatchNormalization)   (None, 19, 19, 512)  2048        conv_66[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_66 (LeakyReLU)            (None, 19, 19, 512)  0           bnorm_66[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_67 (Conv2D)                (None, 19, 19, 1024) 4718592     leaky_66[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_67 (BatchNormalization)   (None, 19, 19, 1024) 4096        conv_67[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_67 (LeakyReLU)            (None, 19, 19, 1024) 0           bnorm_67[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 19, 19, 1024) 0           add_19[0][0]                     \n",
      "                                                                 leaky_67[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_69 (Conv2D)                (None, 19, 19, 512)  524288      add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_69 (BatchNormalization)   (None, 19, 19, 512)  2048        conv_69[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_69 (LeakyReLU)            (None, 19, 19, 512)  0           bnorm_69[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_70 (Conv2D)                (None, 19, 19, 1024) 4718592     leaky_69[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_70 (BatchNormalization)   (None, 19, 19, 1024) 4096        conv_70[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_70 (LeakyReLU)            (None, 19, 19, 1024) 0           bnorm_70[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 19, 19, 1024) 0           add_20[0][0]                     \n",
      "                                                                 leaky_70[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_72 (Conv2D)                (None, 19, 19, 512)  524288      add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_72 (BatchNormalization)   (None, 19, 19, 512)  2048        conv_72[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_72 (LeakyReLU)            (None, 19, 19, 512)  0           bnorm_72[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_73 (Conv2D)                (None, 19, 19, 1024) 4718592     leaky_72[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_73 (BatchNormalization)   (None, 19, 19, 1024) 4096        conv_73[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_73 (LeakyReLU)            (None, 19, 19, 1024) 0           bnorm_73[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 19, 19, 1024) 0           add_21[0][0]                     \n",
      "                                                                 leaky_73[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_75 (Conv2D)                (None, 19, 19, 512)  524288      add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_75 (BatchNormalization)   (None, 19, 19, 512)  2048        conv_75[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_75 (LeakyReLU)            (None, 19, 19, 512)  0           bnorm_75[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_76 (Conv2D)                (None, 19, 19, 1024) 4718592     leaky_75[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_76 (BatchNormalization)   (None, 19, 19, 1024) 4096        conv_76[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_76 (LeakyReLU)            (None, 19, 19, 1024) 0           bnorm_76[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_77 (Conv2D)                (None, 19, 19, 512)  524288      leaky_76[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_77 (BatchNormalization)   (None, 19, 19, 512)  2048        conv_77[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_77 (LeakyReLU)            (None, 19, 19, 512)  0           bnorm_77[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_78 (Conv2D)                (None, 19, 19, 1024) 4718592     leaky_77[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_78 (BatchNormalization)   (None, 19, 19, 1024) 4096        conv_78[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_78 (LeakyReLU)            (None, 19, 19, 1024) 0           bnorm_78[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_79 (Conv2D)                (None, 19, 19, 512)  524288      leaky_78[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_79 (BatchNormalization)   (None, 19, 19, 512)  2048        conv_79[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_79 (LeakyReLU)            (None, 19, 19, 512)  0           bnorm_79[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_80 (Conv2D)                (None, 19, 19, 1024) 4718592     leaky_79[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_80 (BatchNormalization)   (None, 19, 19, 1024) 4096        conv_80[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_80 (LeakyReLU)            (None, 19, 19, 1024) 0           bnorm_80[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_81 (Conv2D)                (None, 19, 19, 425)  435625      leaky_80[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 56,803,337\n",
      "Trainable params: 56,758,409\n",
      "Non-trainable params: 44,928\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "yolo_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "QLQ3At90cmB4"
   },
   "outputs": [],
   "source": [
    "yolo_outputs = yolo_head(yolo_model.output, anchors, len(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "cIxta9IKcoL8"
   },
   "outputs": [],
   "source": [
    "scores, boxes, classes = yolo_eval(yolo_outputs, image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "62ItfAQKcr3B"
   },
   "outputs": [],
   "source": [
    "def predict(sess, image_file):\n",
    "    \"\"\"\n",
    "    Runs the graph stored in \"sess\" to predict boxes for \"image_file\". Prints and plots the predictions.\n",
    "    \n",
    "    Arguments:\n",
    "    sess -- your tensorflow/Keras session containing the YOLO graph\n",
    "    image_file -- name of an image stored in the \"images\" folder.\n",
    "    \n",
    "    Returns:\n",
    "    out_scores -- tensor of shape (None, ), scores of the predicted boxes\n",
    "    out_boxes -- tensor of shape (None, 4), coordinates of the predicted boxes\n",
    "    out_classes -- tensor of shape (None, ), class index of the predicted boxes\n",
    "    \n",
    "    Note: \"None\" actually represents the number of predicted boxes, it varies between 0 and max_boxes. \n",
    "    \"\"\"\n",
    "\n",
    "    # Preprocess your image\n",
    "    image, image_data = preprocess_image(image_file, model_image_size = (608, 608)) #changed model_image_size\n",
    "\n",
    "    # Run the session with the correct tensors and choose the correct placeholders in the feed_dict.\n",
    "    out_scores, out_boxes = sess.run(fetches=[scores, boxes],\n",
    "                                                 feed_dict={yolo_model.input: image_data,\n",
    "                                                           K.learning_phase(): 0})\n",
    "\n",
    "    # Print predictions info\n",
    "    print('Found {} boxes for {}'.format(len(out_boxes), image_file))\n",
    "    # Generate colors for drawing bounding boxes.\n",
    "    colors = generate_colors(class_names)\n",
    "    # Draw bounding boxes on the image file\n",
    "    draw_boxes(image, out_scores, out_boxes, out_classes, class_names, colors)\n",
    "    # Save the predicted bounding box on the image\n",
    "    image.save(os.path.join(\"out\", image_file), quality=90)\n",
    "    \n",
    "    return image, out_scores, out_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "GBlmmbMnlINv"
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Javascript\n",
    "from google.colab.output import eval_js\n",
    "from base64 import b64decode\n",
    "\n",
    "def take_photo(filename='photo.jpg', quality=0.8):\n",
    "  js = Javascript('''\n",
    "    async function takePhoto(quality) {\n",
    "      const div = document.createElement('div');\n",
    "      const capture = document.createElement('button');\n",
    "      capture.textContent = 'Capture';\n",
    "      div.appendChild(capture);\n",
    "\n",
    "      const video = document.createElement('video');\n",
    "      video.style.display = 'block';\n",
    "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
    "\n",
    "      document.body.appendChild(div);\n",
    "      div.appendChild(video);\n",
    "      video.srcObject = stream;\n",
    "      await video.play();\n",
    "\n",
    "      // Resize the output to fit the video element.\n",
    "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
    "\n",
    "      // Wait for Capture to be clicked.\n",
    "      await new Promise((resolve) => capture.onclick = resolve);\n",
    "\n",
    "      const canvas = document.createElement('canvas');\n",
    "      canvas.width = video.videoWidth;\n",
    "      canvas.height = video.videoHeight;\n",
    "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
    "      stream.getVideoTracks()[0].stop();\n",
    "      div.remove();\n",
    "      return canvas.toDataURL('image/jpeg', quality);\n",
    "    }\n",
    "    ''')\n",
    "  display(js)\n",
    "  data = eval_js('takePhoto({})'.format(quality))\n",
    "  binary = b64decode(data.split(',')[1])\n",
    "  with open(filename, 'wb') as f:\n",
    "    f.write(binary)\n",
    "  return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "id": "lxqbBW56lIM9",
    "outputId": "32070115-6212-4ccb-c934-3ef394c3d318"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function takePhoto(quality) {\n",
       "      const div = document.createElement('div');\n",
       "      const capture = document.createElement('button');\n",
       "      capture.textContent = 'Capture';\n",
       "      div.appendChild(capture);\n",
       "\n",
       "      const video = document.createElement('video');\n",
       "      video.style.display = 'block';\n",
       "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
       "\n",
       "      document.body.appendChild(div);\n",
       "      div.appendChild(video);\n",
       "      video.srcObject = stream;\n",
       "      await video.play();\n",
       "\n",
       "      // Resize the output to fit the video element.\n",
       "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
       "\n",
       "      // Wait for Capture to be clicked.\n",
       "      await new Promise((resolve) => capture.onclick = resolve);\n",
       "\n",
       "      const canvas = document.createElement('canvas');\n",
       "      canvas.width = video.videoWidth;\n",
       "      canvas.height = video.videoHeight;\n",
       "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
       "      stream.getVideoTracks()[0].stop();\n",
       "      div.remove();\n",
       "      return canvas.toDataURL('image/jpeg', quality);\n",
       "    }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to photo.jpg\n",
      "type object 'Image' has no attribute 'open'\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "try:\n",
    "  filename = take_photo()\n",
    "  print('Saved to {}'.format(filename))\n",
    "  while True:\n",
    "    img, out_scores, out_boxes = predict(sess, filename)\n",
    "    display(Image(img))\n",
    "    #cv2.imshow(\"Display\", img)        \n",
    "    #if (cv2.waitKey(1) & 0xFF == ord(\"q\")) or (cv2.waitKey(1)==27):\n",
    "      #cv2.destroyAllWindows()\n",
    "      #break\n",
    "#cam.release()\n",
    "#cv2.destroyAllWindows()\n",
    "  \n",
    "  # Show the image which was just taken.\n",
    "except Exception as err:\n",
    "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
    "  # grant the page permission to access it.\n",
    "  print(str(err))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
