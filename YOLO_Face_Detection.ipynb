{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOLO Face Detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMvqNlbyLs0ppWGYtIS7sLo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhaswatib/YOLOv3-Face-Detection/blob/main/YOLO_Face_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQJ8uB_Pcszb"
      },
      "source": [
        "import argparse\n",
        "import os\n",
        "import cv2\n",
        "import colorsys\n",
        "import imghdr\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imshow\n",
        "import scipy.io\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import PIL \n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import struct\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import add, concatenate\n",
        "from tensorflow.keras.layers import Input, Lambda, Conv2D, BatchNormalization, LeakyReLU, ZeroPadding2D, UpSampling2D\n",
        "from tensorflow.keras.models import load_model, Model\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeMMZyTpEGA7"
      },
      "source": [
        "def yolo_filter_boxes(box_confidence, boxes, box_class_probs, threshold = .6):\n",
        "    \"\"\"Filters YOLO boxes by thresholding on object and class confidence.\n",
        "    \n",
        "    Arguments:\n",
        "    box_confidence -- tensor of shape (19, 19, 5, 1)\n",
        "    boxes -- tensor of shape (19, 19, 5, 4)\n",
        "    box_probs -- tensor of shape (19, 19, 5, 1)\n",
        "    threshold -- real value, if [ highest class probability score < threshold], then get rid of the corresponding box\n",
        "    \n",
        "    Returns:\n",
        "    scores -- tensor of shape (None,), containing the class probability score for selected boxes\n",
        "    boxes -- tensor of shape (None, 4), containing (b_x, b_y, b_h, b_w) coordinates of selected boxes    \n",
        "    Note: \"None\" is here because you don't know the exact number of selected boxes, as it depends on the threshold. \n",
        "    For example, the actual output size of scores would be (10,) if there are 10 boxes.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Step 1: Compute box scores\n",
        "    box_scores = box_confidence*box_class_probs\n",
        "    box_classes = K.argmax(box_scores, axis = -1)\n",
        "    box_class_scores = K.max(box_scores,-1)\n",
        "    \n",
        "    \n",
        "    # Step 2: Create a filtering mask based on \"box_scores\" by using \"threshold\". The mask should have the\n",
        "    # same dimension as box_scores, and be True for the boxes you want to keep (with probability >= threshold)\n",
        "    filtering_mask = box_class_scores >= threshold\n",
        "    \n",
        "    \n",
        "    # Step 3: Apply the mask to box_scores and boxes\n",
        "    scores = tf.boolean_mask(box_class_scores, filtering_mask)\n",
        "    boxes = tf.boolean_mask(boxes, filtering_mask)   \n",
        "    classes = tf.boolean_mask(box_classes, filtering_mask)    \n",
        "    \n",
        "    return scores, boxes, classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hi8q4DK2ESmT",
        "outputId": "0805b499-c9af-4f3e-ed6b-7d36bee0a37c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "with  tf.compat.v1.Session() as test_a:\n",
        "    box_confidence = tf.random.normal([19, 19, 5, 1], mean=1, stddev=4, seed = 1)\n",
        "    boxes = tf.random.normal([19, 19, 5, 4], mean=1, stddev=4, seed = 1)\n",
        "    box_class_probs = tf.random.normal([19, 19, 5, 1], mean=1, stddev=4, seed = 1)\n",
        "    scores, boxes, classes = yolo_filter_boxes(box_confidence, boxes, box_class_probs, threshold = 0.5)\n",
        "    print(\"scores[2] = \" + str(scores[2].eval()))\n",
        "    print(\"boxes[2] = \" + str(boxes[2].eval()))\n",
        "    print(\"classes[2] = \" + str(classes[2].eval()))\n",
        "    print(\"scores.shape = \" + str(scores.shape))\n",
        "    print(\"boxes.shape = \" + str(boxes.shape))\n",
        "    print(\"classes.shape = \" + str(classes.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "scores[2] = 1.5909218\n",
            "boxes[2] = [ 8.426533   3.2713668 -0.5313436 -4.9413733]\n",
            "classes[2] = 0\n",
            "scores.shape = (None,)\n",
            "boxes.shape = (None, 4)\n",
            "classes.shape = (None,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4sgBcQjEdg3"
      },
      "source": [
        "def iou(box1, box2):\n",
        "    \"\"\"Implement the intersection over union (IoU) between box1 and box2\n",
        "    \n",
        "    Arguments:\n",
        "    box1 -- first box, list object with coordinates (box1_x1, box1_y1, box1_x2, box_1_y2)\n",
        "    box2 -- second box, list object with coordinates (box2_x1, box2_y1, box2_x2, box2_y2)\n",
        "    \"\"\"\n",
        "\n",
        "    # Assign variable names to coordinates for clarity\n",
        "    (box1_x1, box1_y1, box1_x2, box1_y2) = box1\n",
        "    (box2_x1, box2_y1, box2_x2, box2_y2) = box2\n",
        "        \n",
        "    # Calculate the (yi1, xi1, yi2, xi2) coordinates of the intersection of box1 and box2. Calculate its Area.\n",
        "    xi1 = max(box1[0], box2[0])\n",
        "    yi1 = max(box1[1], box2[1])\n",
        "    xi2 = min(box1[2], box2[2])\n",
        "    yi2 = min(box1[3], box2[3])\n",
        "    inter_width = max(xi2 - xi1, 0)\n",
        "    inter_height = max(yi2 - yi1, 0)\n",
        "    inter_area = inter_width * inter_height \n",
        "        \n",
        "    # Calculate the Union area by using Formula: Union(A,B) = A + B - Inter(A,B)\n",
        "    box1_area = (box1[3] - box1[1])*(box1[2] - box1[0])\n",
        "    box2_area = (box2[3] - box2[1])*(box2[2] - box2[0])\n",
        "    union_area = box1_area + box2_area - inter_area\n",
        "    \n",
        "    # compute the IoU\n",
        "    iou = inter_area / union_area\n",
        "    \n",
        "    return iou"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFDwjxkAEgLo",
        "outputId": "0bc9868e-ca72-40ab-dd39-dab01258022f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "## Test case 1: boxes intersect\n",
        "box1 = (2, 1, 4, 3)\n",
        "box2 = (1, 2, 3, 4) \n",
        "print(\"iou for intersecting boxes = \" + str(iou(box1, box2)))\n",
        "\n",
        "## Test case 2: boxes do not intersect\n",
        "box1 = (1,2,3,4)\n",
        "box2 = (5,6,7,8)\n",
        "print(\"iou for non-intersecting boxes = \" + str(iou(box1,box2)))\n",
        "\n",
        "## Test case 3: boxes intersect at vertices only\n",
        "box1 = (1,1,2,2)\n",
        "box2 = (2,2,3,3)\n",
        "print(\"iou for boxes that only touch at vertices = \" + str(iou(box1,box2)))\n",
        "\n",
        "## Test case 4: boxes intersect at edge only\n",
        "box1 = (1,1,3,3)\n",
        "box2 = (2,3,3,4)\n",
        "print(\"iou for boxes that only touch at edges = \" + str(iou(box1,box2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iou for intersecting boxes = 0.14285714285714285\n",
            "iou for non-intersecting boxes = 0.0\n",
            "iou for boxes that only touch at vertices = 0.0\n",
            "iou for boxes that only touch at edges = 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jrw53WkUEkiP"
      },
      "source": [
        "def yolo_non_max_suppression(scores, boxes, classes, max_boxes = 10, iou_threshold = 0.5):\n",
        "    \"\"\"\n",
        "    Applies Non-max suppression (NMS) to set of boxes\n",
        "    \n",
        "    Arguments:\n",
        "    scores -- tensor of shape (None,), output of yolo_filter_boxes()\n",
        "    boxes -- tensor of shape (None, 4), output of yolo_filter_boxes() that have been scaled to the image size (see later)\n",
        "    max_boxes -- integer, maximum number of predicted boxes you'd like\n",
        "    iou_threshold -- real value, \"intersection over union\" threshold used for NMS filtering\n",
        "    \n",
        "    Returns:\n",
        "    scores -- tensor of shape (, None), predicted score for each box\n",
        "    boxes -- tensor of shape (4, None), predicted box coordinates\n",
        "    \n",
        "    Note: The \"None\" dimension of the output tensors has obviously to be less than max_boxes. Note also that this\n",
        "    function will transpose the shapes of scores, boxes, classes. This is made for convenience.\n",
        "    \"\"\"\n",
        "    \n",
        "    # create max_box_tensor to be used in tf.image.non_max_suppression()\n",
        "    max_boxes_tensor = K.variable(max_boxes, dtype = 'int32')\n",
        "    \n",
        "    # initialize variable max_boxes_tensor\n",
        "    init= tf.compat.v1.variables_initializer([max_boxes_tensor])\n",
        "    #tf.compat.v1.keras.backend.get_session().run(init)\n",
        "    \n",
        "    # Use tf.image.non_max_suppression() to get the list of indices corresponding to boxes you keep\n",
        "    nms_indices = tf.image.non_max_suppression(boxes, scores, max_boxes, iou_threshold)\n",
        "    \n",
        "    # Use K.gather() to select only nms_indices from scores, boxes and classes\n",
        "    scores = K.gather(scores, nms_indices)\n",
        "    boxes = K.gather(boxes, nms_indices)\n",
        "    classes = K.gather(classes, nms_indices)\n",
        "    \n",
        "    return scores, boxes, classes\n",
        "\n",
        "def load_image_pixels(filename, shape):\n",
        "    # load image to get its shape\n",
        "    image = load_img(filename)\n",
        "    width, height = image.size\n",
        "\n",
        "    # load image with required size\n",
        "    image = load_img(filename, target_size=shape)\n",
        "    image = img_to_array(image)\n",
        "\n",
        "    # grayscale image normalization\n",
        "    image = image.astype('float32')\n",
        "    image /= 255.0\n",
        "\n",
        "    # add a dimension so that we have one sample\n",
        "    image = expand_dims(image, 0)\n",
        "    return image, width, height"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoHTa2KTEqSm",
        "outputId": "8aeb5513-1492-458a-a4f9-9f717ed6049e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "with tf.compat.v1.Session() as test_b:\n",
        "    scores = tf.random.normal([54,], mean=1, stddev=4, seed = 1)\n",
        "    boxes = tf.random.normal([54, 4], mean=1, stddev=4, seed = 1)\n",
        "    classes = tf.random.normal([54,], mean=1, stddev=4, seed = 1)\n",
        "    scores, boxes, classes = yolo_non_max_suppression(scores, boxes, classes)\n",
        "    print(\"scores[2] = \" + str(scores[2].eval()))\n",
        "    print(\"boxes[2] = \" + str(boxes[2].eval()))\n",
        "    print(\"classes[2] = \" + str(classes[2].eval()))\n",
        "    print(\"scores.shape = \" + str(scores.eval().shape))\n",
        "    print(\"boxes.shape = \" + str(boxes.eval().shape))\n",
        "    print(\"classes.shape = \" + str(classes.eval().shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "scores[2] = 6.938395\n",
            "boxes[2] = [-5.299932    3.1379814   4.450367    0.95942086]\n",
            "classes[2] = -2.2452729\n",
            "scores.shape = (10,)\n",
            "boxes.shape = (10, 4)\n",
            "classes.shape = (10,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYGQx1weEy28"
      },
      "source": [
        "#Do not make changes in these functions\n",
        "def scale_boxes(boxes, image_shape):\n",
        "    \"\"\" Scales the predicted boxes in order to be drawable on the image\"\"\"\n",
        "    height = image_shape[0]\n",
        "    width = image_shape[1]\n",
        "    image_dims = K.stack([height, width, height, width])\n",
        "    image_dims = K.reshape(image_dims, [1, 4])\n",
        "    boxes = boxes * image_dims\n",
        "    return boxes\n",
        "def yolo_boxes_to_corners(box_xy, box_wh):\n",
        "    \"\"\"Convert YOLO box predictions to bounding box corners.\"\"\"\n",
        "    box_mins = box_xy - (box_wh / 2.)\n",
        "    box_maxes = box_xy + (box_wh / 2.)\n",
        "\n",
        "    return K.concatenate([\n",
        "        box_mins[..., 1:2],  # y_min\n",
        "        box_mins[..., 0:1],  # x_min\n",
        "        box_maxes[..., 1:2],  # y_max\n",
        "        box_maxes[..., 0:1]  # x_max\n",
        "    ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAcIVd4NE3rK"
      },
      "source": [
        "def yolo_head(feats, anchors, num_classes):\n",
        "    \"\"\"Convert final layer features to bounding box parameters.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    feats : tensor\n",
        "        Final convolutional layer features.\n",
        "    anchors : array-like\n",
        "        Anchor box widths and heights.\n",
        "    num_classes : int\n",
        "        Number of target classes.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    box_xy : tensor\n",
        "        x, y box predictions adjusted by spatial location in conv layer.\n",
        "    box_wh : tensor\n",
        "        w, h box predictions adjusted by anchors and conv spatial resolution.\n",
        "    box_conf : tensor\n",
        "        Probability estimate for whether each box contains any object.\n",
        "    box_class_pred : tensor\n",
        "        Probability distribution estimate for each box over class labels.\n",
        "    \"\"\"\n",
        "    num_anchors = len(anchors)\n",
        "    # Reshape to batch, height, width, num_anchors, box_params.\n",
        "    anchors_tensor = K.reshape(K.variable(anchors), [1, 1, 3, num_anchors, 2]) #changed [1, 1, 1, num_anchors, 2] to [1, 1, 3, num_anchors, 2])\n",
        "    # Static implementation for fixed models.\n",
        "    # TODO: Remove or add option for static implementation.\n",
        "    # _, conv_height, conv_width, _ = K.int_shape(feats)\n",
        "    # conv_dims = K.variable([conv_width, conv_height])\n",
        "\n",
        "    # Dynamic implementation of conv dims for fully convolutional model.\n",
        "    conv_dims = K.shape(feats)[1:3]  # assuming channels last\n",
        "    # In YOLO the height index is the inner most iteration.\n",
        "    conv_height_index = K.arange(0, stop=conv_dims[0])\n",
        "    conv_width_index = K.arange(0, stop=conv_dims[1])\n",
        "    conv_height_index = K.tile(conv_height_index, [conv_dims[1]])\n",
        "\n",
        "    # TODO: Repeat_elements and tf.split doesn't support dynamic splits.\n",
        "    # conv_width_index = K.repeat_elements(conv_width_index, conv_dims[1], axis=0)\n",
        "    conv_width_index = K.tile(K.expand_dims(conv_width_index, 0), [conv_dims[0], 1])\n",
        "    conv_width_index = K.flatten(K.transpose(conv_width_index))\n",
        "    conv_index = K.transpose(K.stack([conv_height_index, conv_width_index]))\n",
        "    conv_index = K.reshape(conv_index, [1, conv_dims[0], conv_dims[1], 1, 2])\n",
        "    conv_index = K.cast(conv_index, K.dtype(feats))\n",
        "    \n",
        "    feats = K.reshape(feats, [-1, conv_dims[0], conv_dims[1], num_anchors, num_classes + 5])\n",
        "    conv_dims = K.cast(K.reshape(conv_dims, [1, 1, 1, 1, 2]), K.dtype(feats))\n",
        "\n",
        "    # Static generation of conv_index:\n",
        "    # conv_index = np.array([_ for _ in np.ndindex(conv_width, conv_height)])\n",
        "    # conv_index = conv_index[:, [1, 0]]  # swap columns for YOLO ordering.\n",
        "    # conv_index = K.variable(\n",
        "    #     conv_index.reshape(1, conv_height, conv_width, 1, 2))\n",
        "    # feats = Reshape(\n",
        "    #     (conv_dims[0], conv_dims[1], num_anchors, num_classes + 5))(feats)\n",
        "\n",
        "    box_confidence = K.sigmoid(feats[..., 4:5])\n",
        "    box_xy = K.sigmoid(feats[..., :2])\n",
        "    box_wh = K.exp(feats[..., 2:4])\n",
        "    box_class_probs = K.softmax(feats[..., 5:])\n",
        "\n",
        "    # Adjust preditions to each spatial grid point and anchor size.\n",
        "    # Note: YOLO iterates over height index before width index.\n",
        "    box_xy = (box_xy + conv_index) / conv_dims\n",
        "    box_wh = box_wh * anchors_tensor / conv_dims\n",
        "\n",
        "    return box_confidence, box_xy, box_wh, box_class_probs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUtxHCOgE7hR"
      },
      "source": [
        "def yolo_eval(yolo_outputs, image_shape = (720., 1280.), max_boxes=10, score_threshold=.6, iou_threshold=.5):\n",
        "    \"\"\"\n",
        "    Converts the output of YOLO encoding (a lot of boxes) to your predicted boxes along with their scores, box coordinates and classes.\n",
        "    \n",
        "    Arguments:\n",
        "    yolo_outputs -- output of the encoding model (for image_shape of (608, 608, 3)), contains 4 tensors:\n",
        "                    box_confidence: tensor of shape (None, 19, 19, 5, 1)\n",
        "                    box_xy: tensor of shape (None, 19, 19, 5, 2)\n",
        "                    box_wh: tensor of shape (None, 19, 19, 5, 2)\n",
        "                    box_probs: tensor of shape (None, 19, 19, 5, 1)\n",
        "    image_shape -- tensor of shape (2,) containing the input shape, in this notebook we use (608., 608.) (has to be float32 dtype)\n",
        "    max_boxes -- integer, maximum number of predicted boxes you'd like\n",
        "    score_threshold -- real value, if [ highest probability score < threshold], then get rid of the corresponding box\n",
        "    iou_threshold -- real value, \"intersection over union\" threshold used for NMS filtering\n",
        "    \n",
        "    Returns:\n",
        "    scores -- tensor of shape (None, ), predicted score for each box\n",
        "    boxes -- tensor of shape (None, 4), predicted box coordinates\n",
        "    \"\"\"\n",
        "    \n",
        "    # Retrieve outputs of the YOLO model (≈1 line)\n",
        "    box_confidence, box_xy, box_wh, box_class_probs = yolo_outputs\n",
        "    \n",
        "    # Convert boxes to be ready for filtering functions (convert boxes box_xy and box_wh to corner coordinates)\n",
        "    boxes = yolo_boxes_to_corners(box_xy, box_wh)\n",
        "    \n",
        "    # Use one of the functions you've implemented to perform Score-filtering with a threshold of score_threshold (≈1 line)\n",
        "    scores, boxes, classes = yolo_filter_boxes(box_confidence, boxes, box_class_probs, threshold = score_threshold)\n",
        "    \n",
        "    # Scale boxes back to original image shape.\n",
        "    boxes = scale_boxes(boxes, image_shape)\n",
        "    \n",
        "    # Use one of the functions you've implemented to perform Non-max suppression with \n",
        "    # maximum number of boxes set to max_boxes and a threshold of iou_threshold (≈1 line)\n",
        "    scores, boxes, classes = yolo_non_max_suppression(scores, boxes, classes, max_boxes, iou_threshold)\n",
        "    \n",
        "    return scores, boxes, classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwDzzvQpFBev",
        "outputId": "2ac82768-cbc7-4023-9e9b-191a3fe7d90f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "with tf.compat.v1.Session() as test_b:\n",
        "    yolo_outputs = (tf.random.normal([19, 19, 5, 1], mean=1, stddev=4, seed = 1),\n",
        "                    tf.random.normal([19, 19, 5, 2], mean=1, stddev=4, seed = 1),\n",
        "                    tf.random.normal([19, 19, 5, 2], mean=1, stddev=4, seed = 1),\n",
        "                    tf.random.normal([19, 19, 5, 1], mean=1, stddev=4, seed = 1))\n",
        "    scores, boxes, classes = yolo_eval(yolo_outputs)\n",
        "    print(\"scores[2] = \" + str(scores[2].eval()))\n",
        "    print(\"boxes[2] = \" + str(boxes[2].eval()))\n",
        "    print(\"classes[2] = \" + str(classes[2].eval()))\n",
        "    print(\"scores.shape = \" + str(scores.eval().shape))\n",
        "    print(\"boxes.shape = \" + str(boxes.eval().shape))\n",
        "    print(\"classes.shape = \" + str(classes.eval().shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "scores[2] = 152.75594\n",
            "boxes[2] = [1292.3297  -278.52167 3876.9893  -835.56494]\n",
            "classes[2] = 0\n",
            "scores.shape = (10,)\n",
            "boxes.shape = (10, 4)\n",
            "classes.shape = (10,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGbQlKJKFHqJ"
      },
      "source": [
        "def preprocess_image(img_path, model_image_size):\n",
        "    image = Image.open(img_path)\n",
        "    resized_image = image.resize(tuple(reversed(model_image_size)), Image.BICUBIC)\n",
        "    image_data = np.array(resized_image, dtype='float32')\n",
        "    image_data /= 255.\n",
        "    image_data = np.expand_dims(image_data, 0)  # Add batch dimension.\n",
        "    return image, image_data\n",
        "\n",
        "def draw_boxes(image, out_scores, out_boxes, out_classes, class_names, colors):\n",
        "    \n",
        "    font = ImageFont.truetype(font='font/FiraMono-Medium.otf',size=np.floor(3e-2 * image.size[1] + 0.5).astype('int32'))\n",
        "    thickness = (image.size[0] + image.size[1]) // 300\n",
        "\n",
        "    for i, c in reversed(list(enumerate(out_classes))):\n",
        "        predicted_class = class_names[c]\n",
        "        box = out_boxes[i]\n",
        "        score = out_scores[i]\n",
        "\n",
        "        label = '{} {:.2f}'.format(predicted_class, score)\n",
        "\n",
        "        draw = ImageDraw.Draw(image)\n",
        "        label_size = draw.textsize(label, font)\n",
        "\n",
        "        top, left, bottom, right = box\n",
        "        top = max(0, np.floor(top + 0.5).astype('int32'))\n",
        "        left = max(0, np.floor(left + 0.5).astype('int32'))\n",
        "        bottom = min(image.size[1], np.floor(bottom + 0.5).astype('int32'))\n",
        "        right = min(image.size[0], np.floor(right + 0.5).astype('int32'))\n",
        "        print(label, (left, top), (right, bottom))\n",
        "\n",
        "        if top - label_size[1] >= 0:\n",
        "            text_origin = np.array([left, top - label_size[1]])\n",
        "        else:\n",
        "            text_origin = np.array([left, top + 1])\n",
        "\n",
        "        for i in range(thickness):\n",
        "            draw.rectangle([left + i, top + i, right - i, bottom - i], outline=colors[c])\n",
        "        draw.rectangle([tuple(text_origin), tuple(text_origin + label_size)], fill=colors[c])\n",
        "        draw.text(text_origin, label, fill=(0, 0, 0), font=font)\n",
        "        del draw"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Z9WXy5SFK0_"
      },
      "source": [
        "class WeightReader:\n",
        "\tdef __init__(self, weight_file):\n",
        "\t\twith open(weight_file,'rb') as w_f:\n",
        "\t\t\tmajor,\t= struct.unpack('i', w_f.read(4))\n",
        "\t\t\tminor,\t= struct.unpack('i', w_f.read(4))\n",
        "\t\t\trevision, = struct.unpack('i', w_f.read(4))\n",
        "\t\t\tif (major*10 + minor) >= 2 and major < 1000 and minor < 1000:\n",
        "\t\t\t\tw_f.read(8)\n",
        "\t\t\telse:\n",
        "\t\t\t\tw_f.read(4)\n",
        "\t\t\ttranspose = (major > 1000) or (minor > 1000)\n",
        "\t\t\tbinary = w_f.read()\n",
        "\t\tself.offset = 0\n",
        "\t\tself.all_weights = np.frombuffer(binary, dtype='float32')\n",
        " \n",
        "\tdef read_bytes(self, size):\n",
        "\t\tself.offset = self.offset + size\n",
        "\t\treturn self.all_weights[self.offset-size:self.offset]\n",
        " \n",
        "\tdef load_weights(self, model):\n",
        "\t\tfor i in range(106):\n",
        "\t\t\ttry:\n",
        "\t\t\t\tconv_layer = model.get_layer('conv_' + str(i))\n",
        "\t\t\t\tprint(\"loading weights of convolution #\" + str(i))\n",
        "\t\t\t\tif i not in [81, 93, 105]:\n",
        "\t\t\t\t\tnorm_layer = model.get_layer('bnorm_' + str(i))\n",
        "\t\t\t\t\tsize = np.prod(norm_layer.get_weights()[0].shape)\n",
        "\t\t\t\t\tbeta  = self.read_bytes(size) # bias\n",
        "\t\t\t\t\tgamma = self.read_bytes(size) # scale\n",
        "\t\t\t\t\tmean  = self.read_bytes(size) # mean\n",
        "\t\t\t\t\tvar   = self.read_bytes(size) # variance\n",
        "\t\t\t\t\tweights = norm_layer.set_weights([gamma, beta, mean, var])\n",
        "\t\t\t\tif len(conv_layer.get_weights()) > 1:\n",
        "\t\t\t\t\tbias   = self.read_bytes(np.prod(conv_layer.get_weights()[1].shape))\n",
        "\t\t\t\t\tkernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
        "\t\t\t\t\tkernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
        "\t\t\t\t\tkernel = kernel.transpose([2,3,1,0])\n",
        "\t\t\t\t\tconv_layer.set_weights([kernel, bias])\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tkernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
        "\t\t\t\t\tkernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
        "\t\t\t\t\tkernel = kernel.transpose([2,3,1,0])\n",
        "\t\t\t\t\tconv_layer.set_weights([kernel])\n",
        "\t\t\texcept ValueError:\n",
        "\t\t\t\tprint(\"no convolution #\" + str(i))\n",
        " \n",
        "\tdef reset(self):\n",
        "\t\tself.offset = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8U83BKLxFQ5k"
      },
      "source": [
        "def _conv_block(inp, convs, skip=True):\n",
        "\tx = inp\n",
        "\tcount = 0\n",
        "\tfor conv in convs:\n",
        "\t\tif count == (len(convs) - 2) and skip:\n",
        "\t\t\tskip_connection = x\n",
        "\t\tcount += 1\n",
        "\t\tif conv['stride'] > 1: x = ZeroPadding2D(((1,0),(1,0)))(x) # peculiar padding as darknet prefer left and top\n",
        "\t\tx = Conv2D(conv['filter'],\n",
        "\t\t\t\t   conv['kernel'],\n",
        "\t\t\t\t   strides=conv['stride'],\n",
        "\t\t\t\t   padding='valid' if conv['stride'] > 1 else 'same', # peculiar padding as darknet prefer left and top\n",
        "\t\t\t\t   name='conv_' + str(conv['layer_idx']),\n",
        "\t\t\t\t   use_bias=False if conv['bnorm'] else True)(x)\n",
        "\t\tif conv['bnorm']: x = BatchNormalization(epsilon=0.001, name='bnorm_' + str(conv['layer_idx']))(x)\n",
        "\t\tif conv['leaky']: x = LeakyReLU(alpha=0.1, name='leaky_' + str(conv['layer_idx']))(x)\n",
        "\treturn add([skip_connection, x]) if skip else x\n",
        "\n",
        "def make_yolov3_model():\n",
        "\tinput_image = Input(shape=(608, 608, 3))\n",
        "\t# Layer  0 => 4\n",
        "\tx = _conv_block(input_image, [{'filter': 32, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 0},\n",
        "\t\t\t\t\t\t\t\t  {'filter': 64, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 1},\n",
        "\t\t\t\t\t\t\t\t  {'filter': 32, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 2},\n",
        "\t\t\t\t\t\t\t\t  {'filter': 64, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 3}])\n",
        "\t# Layer  5 => 8\n",
        "\tx = _conv_block(x, [{'filter': 128, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 5},\n",
        "\t\t\t\t\t\t{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 6},\n",
        "\t\t\t\t\t\t{'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 7}])\n",
        "\t# Layer  9 => 11\n",
        "\tx = _conv_block(x, [{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 9},\n",
        "\t\t\t\t\t\t{'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 10}])\n",
        "\t# Layer 12 => 15\n",
        "\tx = _conv_block(x, [{'filter': 256, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 12},\n",
        "\t\t\t\t\t\t{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 13},\n",
        "\t\t\t\t\t\t{'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 14}])\n",
        "\t# Layer 16 => 36\n",
        "\tfor i in range(7):\n",
        "\t\tx = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 16+i*3},\n",
        "\t\t\t\t\t\t\t{'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 17+i*3}])\n",
        "\tskip_36 = x\n",
        "\t# Layer 37 => 40\n",
        "\tx = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 37},\n",
        "\t\t\t\t\t\t{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 38},\n",
        "\t\t\t\t\t\t{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 39}])\n",
        "\t# Layer 41 => 61\n",
        "\tfor i in range(7):\n",
        "\t\tx = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 41+i*3},\n",
        "\t\t\t\t\t\t\t{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 42+i*3}])\n",
        "\tskip_61 = x\n",
        "\t# Layer 62 => 65\n",
        "\tx = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 62},\n",
        "\t\t\t\t\t\t{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 63},\n",
        "\t\t\t\t\t\t{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 64}])\n",
        "\t# Layer 66 => 74\n",
        "\tfor i in range(3):\n",
        "\t\tx = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 66+i*3},\n",
        "\t\t\t\t\t\t\t{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 67+i*3}])\n",
        "\t# Layer 75 => 79\n",
        "\tx = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 75},\n",
        "\t\t\t\t\t\t{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 76},\n",
        "\t\t\t\t\t\t{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 77},\n",
        "\t\t\t\t\t\t{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 78},\n",
        "\t\t\t\t\t\t{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 79}], skip=False)\n",
        "\t# Layer 80 => 82\n",
        "\tyolo_82 = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 80},\n",
        "\t\t\t\t\t\t\t  {'filter':  425, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 81}], skip=False) #filter changed to 425\n",
        " # Layer 83 => 86\n",
        "\tx = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 84}], skip=False)\n",
        "\tx = UpSampling2D(2)(x)\n",
        "\tx = concatenate([x, skip_61])\n",
        "\t# Layer 87 => 91\n",
        "\tx = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 87},\n",
        "\t\t\t\t\t\t{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 88},\n",
        "\t\t\t\t\t\t{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 89},\n",
        "\t\t\t\t\t\t{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 90},\n",
        "\t\t\t\t\t\t{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 91}], skip=False)\n",
        "\t# Layer 92 => 94\n",
        "\tyolo_94 = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 92},\n",
        "\t\t\t\t\t\t\t  {'filter': 425, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 93}], skip=False) #filter changed to 425\n",
        "\t# Layer 95 => 98\n",
        "\tx = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True,   'layer_idx': 96}], skip=False)\n",
        "\tx = UpSampling2D(2)(x)\n",
        "\tx = concatenate([x, skip_36])\n",
        "\t# Layer 99 => 106\n",
        "\tyolo_106 = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 99},\n",
        "\t\t\t\t\t\t\t   {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 100},\n",
        "\t\t\t\t\t\t\t   {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 101},\n",
        "\t\t\t\t\t\t\t   {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 102},\n",
        "\t\t\t\t\t\t\t   {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 103},\n",
        "\t\t\t\t\t\t\t   {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 104},\n",
        "\t\t\t\t\t\t\t   {'filter': 425, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 105}], skip=False) #filter changed to 425\n",
        "\tmodel = Model(input_image, [yolo_82])\n",
        "\treturn model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKNpApPdFUT1",
        "outputId": "cfb26ddb-3bdb-41f9-b680-6777d23ede52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# define the yolo v3 model\n",
        "yolov3 = make_yolov3_model()\n",
        "\n",
        "# load the weights\n",
        "weight_reader = WeightReader('yolov3-wider_16000.weights')\n",
        "\n",
        "# set the weights\n",
        "weight_reader.load_weights(yolov3)\n",
        "\n",
        "# save the model to file\n",
        "yolov3.save('model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading weights of convolution #0\n",
            "loading weights of convolution #1\n",
            "loading weights of convolution #2\n",
            "loading weights of convolution #3\n",
            "no convolution #4\n",
            "loading weights of convolution #5\n",
            "loading weights of convolution #6\n",
            "loading weights of convolution #7\n",
            "no convolution #8\n",
            "loading weights of convolution #9\n",
            "loading weights of convolution #10\n",
            "no convolution #11\n",
            "loading weights of convolution #12\n",
            "loading weights of convolution #13\n",
            "loading weights of convolution #14\n",
            "no convolution #15\n",
            "loading weights of convolution #16\n",
            "loading weights of convolution #17\n",
            "no convolution #18\n",
            "loading weights of convolution #19\n",
            "loading weights of convolution #20\n",
            "no convolution #21\n",
            "loading weights of convolution #22\n",
            "loading weights of convolution #23\n",
            "no convolution #24\n",
            "loading weights of convolution #25\n",
            "loading weights of convolution #26\n",
            "no convolution #27\n",
            "loading weights of convolution #28\n",
            "loading weights of convolution #29\n",
            "no convolution #30\n",
            "loading weights of convolution #31\n",
            "loading weights of convolution #32\n",
            "no convolution #33\n",
            "loading weights of convolution #34\n",
            "loading weights of convolution #35\n",
            "no convolution #36\n",
            "loading weights of convolution #37\n",
            "loading weights of convolution #38\n",
            "loading weights of convolution #39\n",
            "no convolution #40\n",
            "loading weights of convolution #41\n",
            "loading weights of convolution #42\n",
            "no convolution #43\n",
            "loading weights of convolution #44\n",
            "loading weights of convolution #45\n",
            "no convolution #46\n",
            "loading weights of convolution #47\n",
            "no convolution #47\n",
            "loading weights of convolution #48\n",
            "no convolution #48\n",
            "no convolution #49\n",
            "loading weights of convolution #50\n",
            "no convolution #50\n",
            "loading weights of convolution #51\n",
            "no convolution #51\n",
            "no convolution #52\n",
            "loading weights of convolution #53\n",
            "no convolution #53\n",
            "loading weights of convolution #54\n",
            "no convolution #54\n",
            "no convolution #55\n",
            "loading weights of convolution #56\n",
            "no convolution #56\n",
            "loading weights of convolution #57\n",
            "no convolution #57\n",
            "no convolution #58\n",
            "loading weights of convolution #59\n",
            "no convolution #59\n",
            "loading weights of convolution #60\n",
            "no convolution #60\n",
            "no convolution #61\n",
            "loading weights of convolution #62\n",
            "no convolution #62\n",
            "loading weights of convolution #63\n",
            "no convolution #63\n",
            "loading weights of convolution #64\n",
            "no convolution #64\n",
            "no convolution #65\n",
            "loading weights of convolution #66\n",
            "no convolution #66\n",
            "loading weights of convolution #67\n",
            "no convolution #67\n",
            "no convolution #68\n",
            "loading weights of convolution #69\n",
            "no convolution #69\n",
            "loading weights of convolution #70\n",
            "no convolution #70\n",
            "no convolution #71\n",
            "loading weights of convolution #72\n",
            "no convolution #72\n",
            "loading weights of convolution #73\n",
            "no convolution #73\n",
            "no convolution #74\n",
            "loading weights of convolution #75\n",
            "no convolution #75\n",
            "loading weights of convolution #76\n",
            "no convolution #76\n",
            "loading weights of convolution #77\n",
            "no convolution #77\n",
            "loading weights of convolution #78\n",
            "no convolution #78\n",
            "loading weights of convolution #79\n",
            "no convolution #79\n",
            "loading weights of convolution #80\n",
            "no convolution #80\n",
            "loading weights of convolution #81\n",
            "no convolution #81\n",
            "no convolution #82\n",
            "no convolution #83\n",
            "no convolution #84\n",
            "no convolution #85\n",
            "no convolution #86\n",
            "no convolution #87\n",
            "no convolution #88\n",
            "no convolution #89\n",
            "no convolution #90\n",
            "no convolution #91\n",
            "no convolution #92\n",
            "no convolution #93\n",
            "no convolution #94\n",
            "no convolution #95\n",
            "no convolution #96\n",
            "no convolution #97\n",
            "no convolution #98\n",
            "no convolution #99\n",
            "no convolution #100\n",
            "no convolution #101\n",
            "no convolution #102\n",
            "no convolution #103\n",
            "no convolution #104\n",
            "no convolution #105\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtP5t8YAcSoe"
      },
      "source": [
        "sess = tf.compat.v1.keras.backend.get_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQG6zKiXcU67"
      },
      "source": [
        "class_names = [\"Face\"]\n",
        "anchors = [[10,13,  16,30,  33,23], [30,61, 62,45, 59,119], [116,90,  156,198,  373,326]]\n",
        "image_shape = (720., 1280.)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YXoi1hLcYr6"
      },
      "source": [
        "yolo_model = load_model('model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaEK3O7VccNh"
      },
      "source": [
        "yolo_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLQ3At90cmB4"
      },
      "source": [
        "yolo_outputs = yolo_head(yolo_model.output, anchors, len(class_names))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIxta9IKcoL8"
      },
      "source": [
        "scores, boxes, classes = yolo_eval(yolo_outputs, image_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62ItfAQKcr3B"
      },
      "source": [
        "def predict(sess, image_file):\n",
        "    \"\"\"\n",
        "    Runs the graph stored in \"sess\" to predict boxes for \"image_file\". Prints and plots the predictions.\n",
        "    \n",
        "    Arguments:\n",
        "    sess -- your tensorflow/Keras session containing the YOLO graph\n",
        "    image_file -- name of an image stored in the \"images\" folder.\n",
        "    \n",
        "    Returns:\n",
        "    out_scores -- tensor of shape (None, ), scores of the predicted boxes\n",
        "    out_boxes -- tensor of shape (None, 4), coordinates of the predicted boxes\n",
        "    out_classes -- tensor of shape (None, ), class index of the predicted boxes\n",
        "    \n",
        "    Note: \"None\" actually represents the number of predicted boxes, it varies between 0 and max_boxes. \n",
        "    \"\"\"\n",
        "\n",
        "    # Preprocess your image\n",
        "    image, image_data = preprocess_image(image_file, model_image_size = (608, 608)) #changed model_image_size\n",
        "\n",
        "    # Run the session with the correct tensors and choose the correct placeholders in the feed_dict.\n",
        "    out_scores, out_boxes = sess.run(fetches=[scores, boxes],\n",
        "                                                 feed_dict={yolo_model.input: image_data,\n",
        "                                                           K.learning_phase(): 0})\n",
        "\n",
        "    # Print predictions info\n",
        "    print('Found {} boxes for {}'.format(len(out_boxes), image_file))\n",
        "    # Generate colors for drawing bounding boxes.\n",
        "    colors = generate_colors(class_names)\n",
        "    # Draw bounding boxes on the image file\n",
        "    draw_boxes(image, out_scores, out_boxes, out_classes, class_names, colors)\n",
        "    # Save the predicted bounding box on the image\n",
        "    image.save(os.path.join(\"out\", image_file), quality=90)\n",
        "    \n",
        "    return image, out_scores, out_boxes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBlmmbMnlINv"
      },
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxqbBW56lIM9"
      },
      "source": [
        "from IPython.display import Image\n",
        "try:\n",
        "  filename = take_photo()\n",
        "  print('Saved to {}'.format(filename))\n",
        "  while True:\n",
        "    img, out_scores, out_boxes = predict(sess, filename)\n",
        "    display(Image(img))\n",
        "    #cv2.imshow(\"Display\", img)        \n",
        "    #if (cv2.waitKey(1) & 0xFF == ord(\"q\")) or (cv2.waitKey(1)==27):\n",
        "      #cv2.destroyAllWindows()\n",
        "      #break\n",
        "#cam.release()\n",
        "#cv2.destroyAllWindows()\n",
        "  \n",
        "  # Show the image which was just taken.\n",
        "except Exception as err:\n",
        "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "  # grant the page permission to access it.\n",
        "  print(str(err))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}